{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe7e57b",
   "metadata": {},
   "source": [
    "# Implémentation de FOCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa896a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646026c5",
   "metadata": {},
   "source": [
    "$\\textbf{Data}$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e61c3",
   "metadata": {},
   "source": [
    "    Version Windows :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd3c21",
   "metadata": {},
   "source": [
    "        Nouveau jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ab23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_6101_V08 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0008_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V08 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0008_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V13 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0013_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V13 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0013_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V25 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0025_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V25 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0025_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V27 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0027_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V27 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0027_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V40 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0040_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V40 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0040_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V41 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0041_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V41 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0041_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V53 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0053_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V53 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0053_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V54 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0054_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V54 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0054_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V62 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0062_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V62 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0062_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V67 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0067_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V67 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0067_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V68 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0068_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V68 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0068_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V70 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0070_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V70 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0070_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V89 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0089_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V89 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0089_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "Input_6101_V96 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0096_LANDING_input.csv\", sep=\";\")\n",
    "Output_6101_V96 = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/A320_6101_V0096_LANDING_output_5061007F--.csv\", sep=\";\")\n",
    "\n",
    "### convert into numpy array()\n",
    "\n",
    "X_1, Y_1 = Input_6101_V08.to_numpy(), Output_6101_V08.to_numpy()\n",
    "X_2, Y_2 = Input_6101_V13.to_numpy(), Output_6101_V13.to_numpy()\n",
    "X_3, Y_3 = Input_6101_V25.to_numpy(), Output_6101_V25.to_numpy()\n",
    "X_4, Y_4 = Input_6101_V27.to_numpy(), Output_6101_V27.to_numpy()\n",
    "X_5, Y_5 = Input_6101_V40.to_numpy(), Output_6101_V40.to_numpy()\n",
    "X_6, Y_6 = Input_6101_V41.to_numpy(), Output_6101_V41.to_numpy()\n",
    "X_7, Y_7 = Input_6101_V53.to_numpy(), Output_6101_V53.to_numpy()\n",
    "X_8, Y_8 = Input_6101_V54.to_numpy(), Output_6101_V54.to_numpy()\n",
    "X_9, Y_9 = Input_6101_V62.to_numpy(), Output_6101_V62.to_numpy()\n",
    "X_10, Y_10 = Input_6101_V67.to_numpy(), Output_6101_V67.to_numpy()\n",
    "X_11, Y_11 = Input_6101_V68.to_numpy(), Output_6101_V68.to_numpy()\n",
    "X_12, Y_12 = Input_6101_V70.to_numpy(), Output_6101_V70.to_numpy()\n",
    "X_13, Y_13 = Input_6101_V89.to_numpy(), Output_6101_V89.to_numpy()\n",
    "X_14, Y_14 = Input_6101_V96.to_numpy(), Output_6101_V96.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1d118",
   "metadata": {},
   "source": [
    "        Ancien jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaabb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_train = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/X_train_liftoff.csv\", sep=';')\n",
    "Output_train = pd.read_csv(\"C:/Users/emari/Desktop/STAGE IMT 2023/y_train_liftoff.csv\", sep=\";\")\n",
    "\n",
    "X_train = Input_train.to_numpy()\n",
    "Y_train = Output_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dfb75a",
   "metadata": {},
   "source": [
    "    Version Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77ff6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_train = pd.read_csv(\"/home/emilio/Documents/Stage-IMT-2023/First-data-set/X_train_liftoff.csv\", sep=\";\")\n",
    "Output_train = pd.read_csv(\"/home/emilio/Documents/Stage-IMT-2023/First-data-set/y_train_liftoff.csv\", sep=\";\")\n",
    "\n",
    "X_train = Input_train.to_numpy()\n",
    "Y_train = Output_train.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28c237",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cea06",
   "metadata": {},
   "source": [
    "## Estimation by Cramer-Von-Mises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d91e87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85478081",
   "metadata": {},
   "source": [
    "### FOCI algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b48747a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stand = (X_train - np.mean(X_train, axis=0))/np.var(X_train, axis = 0)   ## standardiser les données pour qu'elles soient toutes centrées\n",
    "Y_train_stand = (Y_train[:,1] - np.mean(Y_train[:,1], axis=0))/np.var(Y_train[:,1], axis = 0) ## pareil pour les Outputs \n",
    "\n",
    "memory=500  ## on choisit un fenêtrage pour que nos données utlisées soient iid \n",
    "\n",
    "X_iid = np.zeros((int(X_train.shape[0]/500),X_train.shape[1])) \n",
    "Y_iid = np.zeros(int(Y_train.shape[0]/500))\n",
    "\n",
    "for k in range(int(X_train.shape[0]/500)): ## we have with this shape 100x40 instead of 2000x40 with iid data \n",
    "    X_iid[k,:] = X_train_stand[k*500,:]\n",
    "    Y_iid[k] = Y_train_stand[k*500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfab7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Liste_principale = []   ### List of the inputs index in the decreasing order, raising the dependency between\n",
    "                        ### X and Y\n",
    "    \n",
    "X_iid = np.append(X_iid, np.arange(X_iid.shape[1]).reshape(1,-1), axis=0) ## add a row of arange in our inputs for simplifying\n",
    "                                                                    ## the code\n",
    "Z = X_iid #to keep the notation of the paper\n",
    "Y = Y_iid #same as above\n",
    "n = Z.shape[0] - 1 #number of rows into our model\n",
    "\n",
    "R = np.argsort(Y) #R define below\n",
    "L = n - R  #L define below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f75067",
   "metadata": {},
   "source": [
    "Let $R_i$ be the rank of $Y_i$, that is the number of j such that $Y_j \\leqslant Y_i$.\n",
    "Let $L_i$ be tje inverse of $R_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f2e1f",
   "metadata": {},
   "source": [
    "When X is a list of nothing :\n",
    "\n",
    "$$T_n = T_n(Y, \\textbf{Z}) = \\dfrac{\\sum_i n \\, \\text{min}\\{ R_i, R_{N(i)} \\} - L_i²}{\\sum_i L_i(n-L_i)},$$\n",
    "where $L_i$ is the number of j such that $Y_j \\geq Y_i$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "433975f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list=np.zeros(Z.shape[1]) ## T_list is a list of the permutation N\n",
    "for i in range(Z.shape[1]):\n",
    "    NN = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(Z[:-1,i].reshape(-1,1))\n",
    "\n",
    "    # show the two nearest neighbors of each X in R^n, and take the good neighbor\n",
    "    idx = NN.kneighbors(Z[:-1,i].reshape(-1,1))[1][:,1]\n",
    "\n",
    "    ## Then, use the previous formula, when X = [], to implement the first iteration of FOCI algorithm :\n",
    "    T_list[i] = np.sum(n*np.minimum(R,R[idx]) - L**2)/np.sum(L*(n-L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eec0c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the argmax of all the estimator coefficient is  6\n",
      "This value is  0.9228539576365663\n"
     ]
    }
   ],
   "source": [
    "j_star = np.argmax(T_list) #j_star is the index where Tn as the highest value\n",
    "print(\"the argmax of all the estimator coefficient is \", j_star)\n",
    "print(\"This value is \",T_list[j_star])\n",
    "\n",
    "Liste_principale.append(j_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ea610",
   "metadata": {},
   "source": [
    "When X is not empty :\n",
    "\n",
    "$$T_n = T_n(Y,Z | X) = \\dfrac{\\sum_{i=1}^n \\left( \\text{min}\\{R_i,R_{M(i)}\\} - \\text{min}\\{R_i,R_{N(i)}\\}\\right)}{\\sum_{i=1}^n \\left( R_i - \\text{min}\\{R_i,R_{N(i)}\\}\\right)}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "642dcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = Z # On stocke la valeur de Z dans Z2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d030975",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_=X_iid[:,j_star].reshape(-1,1) # X_ est l'input dont l'indice est j_star \n",
    "idx=j_star\n",
    "Y = Y_iid\n",
    "\n",
    "for l in range(Z2.shape[1]):\n",
    "\n",
    "    ## nouvelles données :\n",
    "    X_ = np.concatenate((X_, Z[:,idx].reshape(-1,1)), axis=1) ## X_ is the conditionnal array in the formula\n",
    "    X_iid = np.delete(X_iid, idx, axis = 1)  #the new Z, without Z[j_star] \n",
    "    Z = X_iid  ## construct the new Z\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(X_[:-1,:])\n",
    "    N = nn.kneighbors(X_)[1][:-1,1]  # la permutation N de l'estimateur      \n",
    "\n",
    "    T_list=np.zeros(Z.shape[1])\n",
    "    for i in range(Z.shape[1]):\n",
    "        NN = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(Z[:-1,i].reshape(-1,1))\n",
    "\n",
    "        # show the two nearest neighbors of each X in R^n\n",
    "        M = NN.kneighbors(Z[:-1,i].reshape(-1,1))[1][:,1]  #la permutation M de l'estimateur\n",
    "\n",
    "        ## Then, use the previous formula, when X != [], to implement the first iteration of FOCI algorithm :\n",
    "\n",
    "        T_list[i] = np.sum(np.minimum(R,R[M]) - np.minimum(R,R[N]))/np.sum(R-np.minimum(R,R[N]))\n",
    "    if T_list.any() == np.zeros(Z.shape[1]).any():\n",
    "        break\n",
    "    \n",
    "    idx = np.argmax(T_list)\n",
    "    j_star = int(X_iid[-1, idx])\n",
    "\n",
    "    Liste_principale = np.append(Liste_principale, j_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "020dabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iid = np.delete(Z2, -1, axis=0) #On reconstruit X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cafd1565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant indices by decreasing order : [ 6  5  4 19 16  9 18  7 13  8 14  0  2 10 20 12 11 17  1 31 26 28 24 32\n",
      " 30 21 29 27 22 15  3 25 23] (33,)\n"
     ]
    }
   ],
   "source": [
    "print(\"relevant indices by decreasing order :\", Liste_principale, np.shape(Liste_principale))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a3524",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d819197d",
   "metadata": {},
   "source": [
    "## FOCI for Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb833f",
   "metadata": {},
   "source": [
    "    Let's now create the signatures, and do the same on the signatures :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b353b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory as sig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bed295",
   "metadata": {},
   "source": [
    "    Create data with signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cfa8ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_data(path, memory, depth_sig):\n",
    "    \n",
    "    print('shape of time considered during calcul of signatures :', memory)\n",
    "    window_data=np.zeros( (memory, path.shape[1]) )\n",
    "    \n",
    "    shape_sig=0\n",
    "    sig_list=[]\n",
    "    for k in range(path.shape[0]):\n",
    "        if k < memory:\n",
    "            window_data=np.zeros( (memory, path.shape[1]) )\n",
    "        else:\n",
    "            window_data=path[k-memory:k,:]\n",
    "        \n",
    "        signatures=signatory.signature( torch.from_numpy(window_data).unsqueeze(0), depth=depth_sig )\n",
    "        sig_list.append(np.array(signatures))\n",
    "        \n",
    "        shape_sig=signatures.shape[1] \n",
    "    \n",
    "    sig_array=np.array(sig_list)\n",
    "    nan_indices = np.where( sig_array != sig_array )\n",
    "    sig_array[nan_indices] = 0\n",
    "    \n",
    "    sig_array=sig_array.squeeze() #for reshape correctly our signatures\n",
    "    \n",
    "    print(\"lenght of one signature :\",shape_sig)\n",
    "    \n",
    "    new_data=np.append(path, sig_array, axis=1)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a76da09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of time considered during calcul of signatures : 500\n",
      "lenght of one signature : 1122\n"
     ]
    }
   ],
   "source": [
    "data_sig = sig_data(X_train, memory=500, depth_sig=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d923b9",
   "metadata": {},
   "source": [
    "    Create iid sample of data with the signatures & the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07de7b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-3248541479e4>:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data_stand = (data_sig - np.mean(data_sig, axis=0))/np.var(data_sig, axis = 0)   ## standardiser les données pour qu'elles soient toutes centrées\n"
     ]
    }
   ],
   "source": [
    "data_stand = (data_sig - np.mean(data_sig, axis=0))/np.var(data_sig, axis = 0)   ## standardiser les données pour qu'elles soient toutes centrées\n",
    "Y_train_stand = (Y_train - np.mean(Y_train, axis=0))/np.var(Y_train, axis = 0)\n",
    "\n",
    "memory=500  ## on choisit un fenêtrage pour que nos données utlisées soient iid \n",
    "\n",
    "data_iid = np.zeros((int(data_stand.shape[0]/500),data_stand.shape[1])) \n",
    "y_train = np.zeros((int(Y_train.shape[0]/500),Y_train.shape[1])) \n",
    "\n",
    "for k in range(int(data_stand.shape[0]/500)): ## we have with this shape 100x40 instead of 2000x40 with iid data \n",
    "    data_iid[k,:] = data_stand[k*500,:]\n",
    "    y_train[k,:] = Y_train_stand[k*500,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2677eb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9d0b8",
   "metadata": {},
   "source": [
    "# TO DO :\n",
    "    \n",
    "    \n",
    "    \n",
    "    Solve the problem of Nan values in data_iid (ie. Z)\n",
    "    \n",
    "    Compute the FOCI algorithm for signatures\n",
    "    \n",
    "    Keep just relevant Inputs indices \n",
    "    \n",
    "    Run an Ordiary Least Squares and look at the R_squared measure to see if we have good results\n",
    "    \n",
    "    Try to understand how to do the same with more than one flight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25e5313b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-4e70f3fb54d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mT_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## T_list is a list of the permutation N\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# show the two nearest neighbors of each X in R^n, and take the good neighbor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_algorithm_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "Liste_principale = []   ### List of the inputs index in the decreasing order, raising the dependency between\n",
    "                        ### X and Y\n",
    "    \n",
    "data_iid = np.append(data_iid, np.arange(data_iid.shape[1]).reshape(1,-1), axis=0) ## add a row of arange in our inputs for simplifying\n",
    "                                                                                   ## the code\n",
    "\n",
    "\n",
    "Z = data_iid #to keep the notation of the paper\n",
    "Y = y_train #same as above\n",
    "n = Z.shape[0] - 1 #number of rows into our model\n",
    "\n",
    "R = np.argsort(Y) #R define below\n",
    "L = n - R  #L define below\n",
    "\n",
    "T_list=np.zeros(Z.shape[1]) ## T_list is a list of the permutation N\n",
    "for i in range(Z.shape[1]):\n",
    "    NN = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(Z[:-1,i].reshape(-1,1))\n",
    "\n",
    "    # show the two nearest neighbors of each X in R^n, and take the good neighbor\n",
    "    idx = NN.kneighbors(Z[:-1,i].reshape(-1,1))[1][:,1]\n",
    "\n",
    "    ## Then, use the previous formula, when X = [], to implement the first iteration of FOCI algorithm :\n",
    "    T_list[i] = np.sum(n*np.minimum(R,R[idx]) - L**2)/np.sum(L*(n-L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_=X_iid[:,j_star].reshape(-1,1) # X_ est l'input dont l'indice est j_star \n",
    "idx=j_star\n",
    "Y = Y_iid\n",
    "\n",
    "for l in range(Z2.shape[1]):\n",
    "\n",
    "    ## nouvelles données :\n",
    "    X_ = np.concatenate((X_, Z[:,idx].reshape(-1,1)), axis=1) ## X_ is the conditionnal array in the formula\n",
    "    X_iid = np.delete(X_iid, idx, axis = 1)  #the new Z, without Z[j_star] \n",
    "    Z = X_iid  ## construct the new Z\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(X_[:-1,:])\n",
    "    N = nn.kneighbors(X_)[1][:-1,1]  # la permutation N de l'estimateur      \n",
    "\n",
    "    T_list=np.zeros(Z.shape[1])\n",
    "    for i in range(Z.shape[1]):\n",
    "        NN = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(Z[:-1,i].reshape(-1,1))\n",
    "\n",
    "        # show the two nearest neighbors of each X in R^n\n",
    "        M = NN.kneighbors(Z[:-1,i].reshape(-1,1))[1][:,1]  #la permutation M de l'estimateur\n",
    "\n",
    "        ## Then, use the previous formula, when X != [], to implement the first iteration of FOCI algorithm :\n",
    "\n",
    "        T_list[i] = np.sum(np.minimum(R,R[M]) - np.minimum(R,R[N]))/np.sum(R-np.minimum(R,R[N]))\n",
    "    if T_list.any() == np.zeros(Z.shape[1]).any():\n",
    "        break\n",
    "    \n",
    "    idx = np.argmax(T_list)\n",
    "    j_star = int(X_iid[-1, idx])\n",
    "\n",
    "    Liste_principale = np.append(Liste_principale, j_star)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
